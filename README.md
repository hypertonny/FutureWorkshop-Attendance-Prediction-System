<div align="center">

# ğŸ¯ FutureWorkshop â€” Attendance Prediction System

**Predict. Plan. Pack the room.**

[![Python](https://img.shields.io/badge/Python-3.12-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)](https://streamlit.io)
[![XGBoost](https://img.shields.io/badge/XGBoost-ML-189FDD?style=for-the-badge&logo=xgboost&logoColor=white)](https://xgboost.readthedocs.io)
[![SQLite](https://img.shields.io/badge/SQLite-Database-003B57?style=for-the-badge&logo=sqlite&logoColor=white)](https://sqlite.org)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

<br>

*An ML-powered system built for **Vijaybhoomi University** that predicts student turnout for FutureWorkshop events â€” helping organizers plan better workshops, allocate resources, and boost engagement across all four schools.*

<br>

[ğŸš€ Quick Start](#-quick-start) Â· [ğŸ“Š Dashboard](#-dashboard) Â· [ğŸ—ï¸ Architecture](#ï¸-architecture) Â· [ğŸ§  How It Works](#-how-it-works) Â· [ğŸ“ Project Structure](#-project-structure)

</div>

---

## â“ The Problem

At **Vijaybhoomi University**, we run **FutureWorkshop** events regularly â€” bringing in industry professionals, alumni, and domain experts as guest speakers to share real-world knowledge with students across all four schools.

The problem is painfully simple:

> *"We invited a guest speaker who flew in from Bangalore. 80 students registered. 15 showed up. The auditorium was embarrassingly empty."*

When a guest takes time out of their schedule to come speak at our campus, they deserve to see a room full of engaged students â€” not rows of empty chairs. And when students *do* show up, they deserve a well-organized event, not a chaotic scramble because we overbooked.

**We can't over-book our auditorium** (fire safety, seating limits), but we also can't afford to under-prepare. Without a reliable prediction of actual turnout, organizers are stuck guessing â€” and that leads to:

- **Wasted resources** â€” catering, printed materials, AV setup for a crowd that never comes
- **Embarrassed guests** â€” speakers who prepared for 100 people but present to 20
- **Missed learning** â€” if we knew turnout would be low, we could have promoted harder or rescheduled
- **Over-booking risk** â€” accepting 200 registrations for a 120-seat auditorium because "only half will come" is a gamble

With four distinct schools (Technology, Design, Business, Music) running cross-disciplinary workshops on 16 different topics, the attendance pattern isn't random â€” it's *predictable*. A Data Science talk will pack the room with Tech students but barely draw from Music. An industry speaker on a weekday afternoon during exams? Expect a ghost town.

**This system turns that guesswork into a data-driven prediction.**

---

## ğŸ’¡ The Solution

A machine learning pipeline that learns from **historical attendance patterns** â€” which topics draw which schools, how speaker type affects turnout, whether exam season kills attendance â€” and predicts how many students will *actually* walk through the auditorium doors for a new event.

**For organizers:** Know in advance if you'll get 30 or 130 â€” plan seating, catering, and promotion accordingly.  
**For guest speakers:** Walk into a room that's full, not half-empty. Their time and expertise deserve that respect.

### Vijaybhoomi University â€” 4 Schools

| School | Domain Topics |
|--------|--------------|
| ğŸ–¥ï¸ **School of Technology** | Data Science, ML, AI & Deep Learning, Web Dev, Cybersecurity, Cloud Computing |
| ğŸ¨ **School of Design** | UI/UX Design, Design Thinking, Branding & Identity, Creative Coding |
| ğŸ’¼ **School of Business** | Entrepreneurship, Digital Marketing, Product Management |
| ğŸµ **School of Music** | Music Production, Sound Design |

The model captures **school-topic affinity** â€” e.g., Technology students are more likely to attend a Data Science workshop, while Design students gravitate toward UI/UX events.

### Key Features

| Feature | Description |
|---------|-------------|
| ğŸ¤– **3-Model Comparison** | XGBoost + Random Forest + Logistic Regression â€” automatically picks the winner by F1 |
| ğŸ“Š **69 Engineered Features** | From 19 raw columns â†’ rich behavioral signals including school-topic affinity |
| ğŸ« **Cross-School Intelligence** | School-topic affinity modeling for all 4 VBU schools & 16 workshop topics |
| ğŸ§ª **Standalone Data Generator** | Synthesize realistic data from scratch â€” no CSV needed |
| â™»ï¸ **Auto-Retraining Pipeline** | Hot-swap models with 1% improvement gate |
| ğŸ“Š **Interactive Dashboard** | 5-page Streamlit app with predictions, analytics & splash screen |
| ğŸ—„ï¸ **Scalable Database** | SQLite now, PostgreSQL-ready (just change one line) |
| âš–ï¸ **Imbalanced Data Handling** | SMOTE + threshold optimization for real-world skew |
| ğŸ”„ **Fresh-Clone Ready** | `python main.py` auto-generates data if CSV is missing |

---

## ğŸš€ Quick Start

```bash
# 1. Clone the repo
git clone https://github.com/hypertonny/FutureWorkshop-Attendance-Prediction-System.git
cd FutureWorkshop-Attendance-Prediction-System

# 2. Create virtual environment
python -m venv .venv
.venv\Scripts\activate        # Windows
# source .venv/bin/activate   # macOS/Linux

# 3. Install dependencies
pip install -r requirements.txt

# 4. Initialize DB + Train models (auto-generates data if CSV is missing)
python main.py

# 5. Launch the dashboard
streamlit run app.py
```

> No CSV file needed â€” `main.py` auto-generates synthetic data on a fresh clone.
> The dashboard opens at **http://localhost:8501** ğŸ‰

### ğŸ“¦ Data Source & Synthesis

This project uses **synthetically generated data** â€” no external download required.  
The script [`generate_data.py`](generate_data.py) creates realistic workshop attendance records from scratch using probability-based rules that mimic real student behavior at Vijaybhoomi University:

- **500 students** across 4 VBU schools, each with randomized CGPA, club activity, and semester
- **100 workshop events** spanning 16 cross-school topics, with varied speakers, time slots, and modes
- **~8 000 registrations** with attendance determined by 10+ realistic factors (club activity, speaker type, exam proximity, topic popularity, registration timing, etc.)

> On a fresh clone, `python main.py` calls `generate_data.py` automatically if no CSV exists â€” the repo is fully self-contained.

### Data Generator CLI

```bash
# Generate from scratch with custom params
python generate_data.py --students 300 --events 50 --seed 123

# Regenerate attendance for existing CSV
python generate_data.py --regenerate

# Full help
python generate_data.py --help
```

---

## ğŸ“Š Dashboard

The Streamlit dashboard has **5 interactive pages** with a branded splash screen and lazy-load animations:

| Page | What it does |
|------|-------------|
| ğŸ  **Overview** | Key metrics, attendance by topic & day-of-week charts |
| ğŸ”® **Predict Attendance** | Enter event details â†’ get predicted turnout + confidence |
| ğŸ“ˆ **Attendance Trends** | Monthly trends, exam impact, speaker & time slot analysis |
| ğŸ” **Topic Analysis** | Deep-dive into any topic â€” department, semester, mode breakdown |
| âš™ï¸ **Model Performance** | 3-model comparison table, bar chart, radar chart, feature importance |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  master_dataset  â”‚â”€â”€â”€â”€â–¶â”‚  Feature Engine   â”‚â”€â”€â”€â”€â–¶â”‚   Model Training    â”‚
â”‚     .csv         â”‚     â”‚  (19 â†’ 69 feat)  â”‚     â”‚  XGB + RF + LR      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                        â”‚                         â”‚
        â”‚              school-topic affinity                â”‚
        â”‚              16 topics Ã— 4 schools                â”‚
        â”‚                                                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SQLite DB   â”‚     â”‚  Best Model .pkl â”‚     â”‚  Streamlit App   â”‚
â”‚  (normalized)â”‚     â”‚  + metadata.json â”‚â”€â”€â”€â”€â–¶â”‚  (5 pages)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  Retrain Pipelineâ”‚
                     â”‚  (hot-swap)      â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  How It Works

### Feature Engineering Pipeline

Raw data has weak correlations (~0.08). The pipeline creates **5 categories** of derived features:

| Category | Examples | Why it helps |
|----------|----------|-------------|
| â° **Temporal** | `semester_week`, `is_weekend`, `month` | Attendance drops late in semester |
| ğŸ‘¤ **Student History** | `rolling_attendance`, `streak`, `recent_3_rate` | Past behavior predicts future |
| ğŸ”¥ **Event Popularity** | `topic_popularity`, `speaker_pull`, `dept_engagement` | Some topics just hit different |
| ğŸ« **School-Topic Affinity** | `dept_topic_match` | Tech students â†’ Data Science, Design students â†’ UI/UX |
| ğŸ”— **Interactions** | `combined_quality_attract`, `exam_pressure`, `registration_commitment` | Combined effects matter |

### Model Training

```
Raw Data â†’ NaN Imputation (median) â†’ SMOTE (if imbalanced)
    â†’ Train XGBoost + Random Forest + Logistic Regression
    â†’ Threshold Sweep (0.10 â†’ 0.60)
    â†’ Compare all 3 by F1 â†’ Save winner
```

- **3 Models**: XGBoost (gradient boosting), Random Forest (bagging), Logistic Regression (linear baseline with StandardScaler)
- **NaN Handling**: Remaining NaN filled with column medians for LR/RF compatibility
- **SMOTE**: Only applied when minority class < 35%
- **Threshold Optimization**: Sweeps 0.10â€“0.60, picks threshold that maximizes F1
- **5-Fold Cross Validation**: Ensures scores aren't just lucky splits
- **Winner Selection**: Best F1 score wins, all 3 models saved for comparison

### Retraining Pipeline

```bash
python src/retrain.py              # retrain from CSV
python src/retrain.py --from-db    # retrain from database
python src/retrain.py --force      # force deploy regardless
```

The pipeline only promotes a new model if it beats the current one by **â‰¥ 1% F1** â€” preventing unnecessary swaps from random variance.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ main.py                    # Entry point: auto-generate data â†’ init DB â†’ train
â”œâ”€â”€ app.py                     # Streamlit dashboard (5 pages, splash screen)
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ generate_data.py           # Standalone data generator (CLI + programmatic)
â”œâ”€â”€ master_dataset.csv         # Training data (auto-generated if missing)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database.py            # SQLAlchemy ORM (4 tables)
â”‚   â”œâ”€â”€ feature_engineering.py # 19 raw â†’ 69 features (incl. school-topic affinity)
â”‚   â”œâ”€â”€ train_model.py         # XGBoost + RF + LR training + NaN imputation
â”‚   â”œâ”€â”€ retrain.py             # Hot-retraining pipeline (1% improvement gate)
â”‚   â””â”€â”€ predict.py             # Prediction engine (handles missing columns)
â”‚
â”œâ”€â”€ models/                    # Auto-generated
â”‚   â”œâ”€â”€ *_latest.pkl           # Trained model files
â”‚   â”œâ”€â”€ *_latest_meta.json     # Model metadata
â”‚   â””â”€â”€ model_comparison.json  # 3-model comparison results
â”‚
â””â”€â”€ data/                      # Auto-generated (gitignored)
    â””â”€â”€ workshop.db            # SQLite database
```

---

## ğŸ“Š Current Model Performance

| Model | F1 Score | AUC-ROC | Accuracy |
|-------|----------|---------|----------|
| XGBoost | 0.733 | 0.778 | 0.656 |
| Random Forest | 0.736 | 0.785 | 0.683 |
| **Logistic Regression (Winner)** | **0.748** | **0.801** | **0.683** |

> F1 is the primary metric â€” accuracy alone is misleading with imbalanced data.
> Winner is auto-selected by highest F1 score. Results vary by seed.
> Trained on 4 VBU schools with 16 cross-school FutureWorkshop topics.

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|-----------|
| **ML Models** | XGBoost, Random Forest, Logistic Regression (scikit-learn) |
| **Data Balancing** | SMOTE (imbalanced-learn) |
| **Database** | SQLite via SQLAlchemy ORM |
| **Dashboard** | Streamlit + Plotly |
| **Data Processing** | Pandas, NumPy |
| **Visualization** | Plotly, Matplotlib, Seaborn |
| **Serialization** | Joblib |

---

## ğŸ”® Future Improvements

- [ ] Integrate with college LMS / Google Forms for real data
- [ ] Student-level prediction (which specific students will attend)
- [ ] Email/notification system for low predicted turnout
- [ ] Deploy on cloud with scheduled retraining
- [ ] A/B testing for promotion strategies
- [ ] Add weather data for offline event predictions
- [ ] Per-student prediction (which specific students will attend)
- [ ] CGPA integration from university records

---

## ğŸ—“ï¸ Updation & Maintenance Timelines

| Phase | Frequency | Trigger | Action |
|-------|-----------|---------|--------|
| **ğŸ”„ Model Retraining** | Every semester start | New semester (Aug / Jan) | `python src/retrain.py` |
| **ğŸ“Š Data Refresh** | After every 10+ events | New attendance logged | `python src/retrain.py --from-db` |
| **ğŸ” Performance Audit** | Monthly | Accuracy drops below threshold | Review features + threshold sweep |
| **ğŸ§¹ Data Cleanup** | End of each semester | Semester ends | Archive old data, regenerate baseline |
| **ğŸš€ Feature Updates** | As needed | New data sources (LMS, weather) | Update `feature_engineering.py`, retrain |
| **ğŸ›¡ï¸ Dependency Updates** | Quarterly | Security patches / new releases | Update `requirements.txt`, test pipeline |

**Retraining safeguard:** The retrain pipeline only deploys a new model if it beats the current one by **â‰¥ 1 % F1 score**, preventing unnecessary swaps from random variance.

---

<div align="center">

### Built with â˜• by Rahul Purohit

*Reg: 2024SEPVUGP0079 Â· School of Technology â€” Vijaybhoomi University*

<br>

â­ **Star this repo if you found it useful!** â­

</div>
